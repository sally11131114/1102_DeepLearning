{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw9pn13Soelk"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dt7exQqxmqer"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXPz9hNdmyub"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gibU_vXum8FC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded the assignment\n",
    "# Example: If you create a 2021DL folder and put all the files under A0 folder, then '2021DL/A0'\n",
    "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'DL2021/midterm2022/DataPrepare'\n",
    "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
    "\n",
    "import sys\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "import time, os\n",
    "os.environ[\"TZ\"] = \"UTC\"\n",
    "time.tzset()\n",
    "\n",
    "from pytorch_autograd_and_nn_sol_new import * # select your function\n",
    "from a4_helper import *\n",
    "hello()\n",
    "\n",
    "py_path = os.path.join(GOOGLE_DRIVE_PATH, 'pytorch_autograd_and_nn_sol_new.py') # select your function\n",
    "py_edit_time = time.ctime(os.path.getmtime(py_path))\n",
    "print('pytorch_autograd_and_nn.py last edited on %s' % py_edit_time)\n",
    "\n",
    "!pip install pytorch-lightning --quiet\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLelCjCYonLF"
   },
   "source": [
    "# CIFAR-100 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WidXoR8Jm_a9"
   },
   "outputs": [],
   "source": [
    "class CIFAR100DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, data_dir: str = './data'):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                                    transforms.RandomHorizontalFlip(),\n",
    "                                                    transforms.RandomRotation(15),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))\n",
    "                                                  ])\n",
    "        \n",
    "        self.transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                                    transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))\n",
    "                                                  ])\n",
    "\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        # download \n",
    "        torchvision.datasets.CIFAR100(self.data_dir, train=True, download=True)\n",
    "        torchvision.datasets.CIFAR100(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            cifar_full = torchvision.datasets.CIFAR100(self.data_dir, train=True, transform=self.transform_train)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.cifar_test = torchvision.datasets.CIFAR100(self.data_dir, train=False, transform=self.transform_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=self.batch_size, num_workers=2)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=16, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZ-4OMiFnAK9"
   },
   "outputs": [],
   "source": [
    "# Init our data pipeline\n",
    "dm = CIFAR100DataModule(batch_size=256)\n",
    "\n",
    "# To access the x_dataloader we need to call prepare_data and setup.\n",
    "dm.prepare_data()\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "testloader = dm.test_dataloader()\n",
    "valloader = dm.val_dataloader()\n",
    "trainloader = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAFvOosjnKIm"
   },
   "outputs": [],
   "source": [
    "#function to read files present in the Python version of the dataset\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        myDict = pickle.load(fo, encoding='latin1')\n",
    "    return myDict\n",
    "\n",
    "metaData = unpickle('/content/data/cifar-100-python/meta')\n",
    "label_names = metaData['fine_label_names']\n",
    "print('Number of class is ', len(label_names))\n",
    "\n",
    "# get some random test images to see if things are getting displayed correctly\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "labels_list = labels.tolist()\n",
    "\n",
    "plt_need_idx = 5\n",
    "print( 'Index of corresponding label is ', labels_list[plt_need_idx] )\n",
    "print( 'Figure size is ', images[plt_need_idx].numpy().shape )\n",
    "print( 'Corresponding label is ', label_names[labels_list[plt_need_idx]] )\n",
    "plt.imshow(np.transpose(images[plt_need_idx].numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC7FWMTLoHjT"
   },
   "source": [
    "# New Train Model (change train_part345 to train_part_NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7C85M9wQnk-z"
   },
   "outputs": [],
   "source": [
    "def check_accuracy_part_NEW(loader, model):  \n",
    "  num_correct = 0\n",
    "  num_samples = 0\n",
    "  model.eval()  # set model to evaluation mode\n",
    "  with torch.no_grad():\n",
    "    for x, y in loader:\n",
    "      x = x.to(device='cuda', dtype=to_float)  # move to device, e.g. GPU\n",
    "      y = y.to(device='cuda', dtype=to_long)\n",
    "      scores = model(x)\n",
    "      _, preds = scores.max(1)\n",
    "      num_correct += (preds == y).sum()\n",
    "      num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "  return acc\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, lrd, epoch, schedule):\n",
    "  \"\"\"\n",
    "  Multiply lrd to the learning rate if epoch is in schedule\n",
    "  \n",
    "  Inputs:\n",
    "  - optimizer: An Optimizer object we will use to train the model\n",
    "  - lrd: learning rate decay; a factor multiplied at scheduled epochs\n",
    "  - epochs: the current epoch number\n",
    "  - schedule: the list of epochs that requires learning rate update\n",
    "  \n",
    "  Returns: Nothing, but learning rate might be updated\n",
    "  \"\"\"\n",
    "  if epoch in schedule:\n",
    "    for param_group in optimizer.param_groups:\n",
    "      print('lr decay from {} to {}'.format(param_group['lr'], param_group['lr'] * lrd))\n",
    "      param_group['lr'] *= lrd\n",
    "\n",
    "\n",
    "def train_part_NEW(model, optimizer, epochs=1, learning_rate_decay=.1, schedule=[], verbose=True):\n",
    "  \"\"\"\n",
    "  Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "  \n",
    "  Inputs:\n",
    "  - model: A PyTorch Module giving the model to train.\n",
    "  - optimizer: An Optimizer object we will use to train the model\n",
    "  - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "  \n",
    "  Returns: Nothing, but prints model accuracies during training.\n",
    "  \"\"\"\n",
    "  model = model.to(device='cuda')  # move the model parameters to CPU/GPU\n",
    "  num_iters = epochs * len(trainloader)\n",
    "  print_every = 100\n",
    "  if verbose:\n",
    "    num_prints = num_iters // print_every + 1\n",
    "  else:\n",
    "    num_prints = epochs\n",
    "  acc_history = torch.zeros(num_prints, dtype=to_float)\n",
    "  iter_history = torch.zeros(num_prints, dtype=to_long)\n",
    "  for e in range(epochs):\n",
    "    \n",
    "    adjust_learning_rate(optimizer, learning_rate_decay, e, schedule)\n",
    "    \n",
    "    for t, (x, y) in enumerate(trainloader):\n",
    "      model.train()  # put model to training mode\n",
    "      x = x.to(device='cuda', dtype=to_float)  # move to device, e.g. GPU\n",
    "      y = y.to(device='cuda', dtype=to_long)\n",
    "\n",
    "      scores = model(x)\n",
    "      loss = F.cross_entropy(scores, y)\n",
    "\n",
    "      # Zero out all of the gradients for the variables which the optimizer\n",
    "      # will update.\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # This is the backwards pass: compute the gradient of the loss with\n",
    "      # respect to each  parameter of the model.\n",
    "      loss.backward()\n",
    "\n",
    "      # Actually update the parameters of the model using the gradients\n",
    "      # computed by the backwards pass.\n",
    "      optimizer.step()\n",
    "\n",
    "      tt = t + e * len(trainloader)\n",
    "      ee = e + 1\n",
    "      if verbose and (tt % print_every == 0 or (e == epochs-1 and t == len(trainloader)-1)):\n",
    "        print('Epoch %d, Iteration %d, loss = %.4f' % (ee, tt, loss.item()))\n",
    "        acc = check_accuracy_part_NEW(valloader, model)\n",
    "        acc_history[tt // print_every] = acc\n",
    "        iter_history[tt // print_every] = tt\n",
    "        print()\n",
    "      elif not verbose and (t == len(trainloader)-1):\n",
    "        print('Epoch %d, Iteration %d, loss = %.4f' % (ee, tt, loss.item()))\n",
    "        acc = check_accuracy_part_NEW(valloader, model)\n",
    "        acc_history[e] = acc\n",
    "        iter_history[e] = tt\n",
    "        print()\n",
    "\n",
    "  torch.save(model.state_dict(), \"/content/drive/MyDrive/DL2021/midterm2022/DataPrepare/saveNEW.pt\")\n",
    "  print('Save model weight')\n",
    "\n",
    "  return acc_history, iter_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWDpWUIOn-BU"
   },
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4A4z8Q9nqRt"
   },
   "outputs": [],
   "source": [
    "# Init our model\n",
    "names = ['resnet47']\n",
    "\n",
    "name = names[-1]\n",
    "reset_seed(0)\n",
    "print(name, '\\n')\n",
    "model = get_resnet(name)\n",
    "  \n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=.9, weight_decay=1e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "acc_history, iter_history = train_part_NEW(model, optimizer, epochs=20, schedule=[10, 20, 40, 80], verbose=False)\n",
    "acc_history_dict[name] = acc_history\n",
    "iter_history_dict[name] = iter_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZEiNaYJn50r"
   },
   "source": [
    "# Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDH7_ukXns4z"
   },
   "outputs": [],
   "source": [
    "plt.title('Val accuracies')\n",
    "for name in names:\n",
    "  plt.plot(iter_history_dict[name], acc_history_dict[name], '-o')\n",
    "plt.legend(names, loc='upper left')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('accuracy')\n",
    "plt.gcf().set_size_inches(9, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jhl96hPcoW1j"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsZyI8IMnv6X"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import *\n",
    "\n",
    "classes = ['beaver', 'dolphin', 'otter', 'seal', 'whale', \n",
    "'aquarium' ,'fish', 'ray', 'shark', 'trout', \n",
    "'orchids', 'poppies', 'roses', 'sunflowers', 'tulips', \n",
    "'bottles', 'bowls', 'cans', 'cups', 'plates', \n",
    "'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers', \n",
    "'clock', 'computer keyboard', 'lamp', 'telephone', 'television', 'bed', 'chair', 'couch', 'table', 'wardrobe', \n",
    "'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach', \n",
    "'bear', 'leopard', 'lion', 'tiger', 'wolf', \n",
    "'bridge', 'castle', 'house', 'road', 'skyscraper', \n",
    "'cloud', 'forest', 'mountain', 'plain', 'sea', \n",
    "'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo', \n",
    "'fox', 'porcupine', 'possum', 'raccoon', 'skunk', \n",
    "'crab', 'lobster', 'snail', 'spider', 'worm', \n",
    "'baby', 'boy', 'girl', 'man', 'woman', \n",
    "'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', \n",
    "'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel', \n",
    "'maple', 'oak', 'palm', 'pine', 'willow', \n",
    "'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train', \n",
    "'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \",device)\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "def test_label_predictions(model, device, testloader):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            actuals.extend(target.view_as(prediction))\n",
    "            predictions.extend(prediction)\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "\n",
    "actualsTrain, predictionsTrain = test_label_predictions(model, device, trainloader)\n",
    "print('Train Dataset Accuracy: %f' % accuracy_score(actualsTrain, predictionsTrain))\n",
    "\n",
    "actualsVal, predictionsVal = test_label_predictions(model, device, valloader)\n",
    "print('Val. Dataset Accuracy: %f' % accuracy_score(actualsVal, predictionsVal))\n",
    "\n",
    "actualsTest, predictionsTest = test_label_predictions(model, device, testloader)\n",
    "print('Test Dataset Accuracy: %f' % accuracy_score(actualsTest, predictionsTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88AZDY7SnwjV"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(actualsTest, predictionsTest)\n",
    "print(cm)\n",
    "fig = plt.figure(figsize=(24,24))\n",
    "ax = fig.add_subplot(211)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + classes)\n",
    "ax.set_yticklabels([''] + classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNdmGX/7VBg7ymYqbVioGrt",
   "collapsed_sections": [
    "Iw9pn13Soelk",
    "BLelCjCYonLF",
    "MC7FWMTLoHjT",
    "sWDpWUIOn-BU",
    "zZEiNaYJn50r",
    "Jhl96hPcoW1j"
   ],
   "name": "Train.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
